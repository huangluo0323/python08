<!DOCTYPE HTML>
<html lang="zh-hans" >
    <!-- Start book 爬虫 -->
    <head>
        <!-- head:start -->
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>CrawlSpider | 爬虫</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-splitter/splitter.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-tbfed-pagefooter/footer.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-emphasize/plugin.css">
        
    
        
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-mcqx/mcqx.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-katex/katex.min.css">
        
    
        
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fbqx/fbqx.css">
        
    
        
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-sectionx/sectionx.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../files/scrapy06.html" />
    
    
    <link rel="prev" href="../files/scrapy04.html" />
    

        <!-- head:end -->
    </head>
    <body>
        <!-- body:start -->
        
    <div class="book"
        data-level="5.5"
        data-chapter-title="CrawlSpider"
        data-filepath="files/scrapy05.md"
        data-basepath=".."
        data-revision="Thu Mar 28 2019 01:32:46 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="files/readme.html">
            
                
                    <a href="../files/readme.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        爬虫基础
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="files/spider01.html">
            
                
                    <a href="../files/spider01.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫基本原理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="files/spider02.html">
            
                
                    <a href="../files/spider02.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        python3编码问题
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="files/spider03.html">
            
                
                    <a href="../files/spider03.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        requests基础应用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="files/spider04.html">
            
                
                    <a href="../files/spider04.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        requests进阶
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="files/spider05.html">
            
                
                    <a href="../files/spider05.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.5.</b>
                        
                        抓包工具fiddler
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="files/spider06.html">
            
                
                    <a href="../files/spider06.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.6.</b>
                        
                        了解:urllib
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="files/jiexi.html">
            
                
                    <a href="../files/jiexi.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        爬虫解析库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="files/re.html">
            
                
                    <a href="../files/re.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        正则表达式
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="files/re0.html">
            
                
                    <a href="../files/re0.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        正则表达式案例
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="files/xpath0.html">
            
                
                    <a href="../files/xpath0.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        xpath
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="files/xpath01.html">
            
                
                    <a href="../files/xpath01.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        xpath案例
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="files/bs01.html">
            
                
                    <a href="../files/bs01.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                        beautiful soup(了解)
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="files/bs02.html">
            
                
                    <a href="../files/bs02.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.</b>
                        
                        beautiful soup案例
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="files/shuju.html">
            
                
                    <a href="../files/shuju.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        数据存储
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="files/txt.html">
            
                
                    <a href="../files/txt.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        txt文件存储
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="files/json.html">
            
                
                    <a href="../files/json.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        json文件存储
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="files/csv.html">
            
                
                    <a href="../files/csv.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        csv文件存储
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="files/threading.html">
            
                
                    <a href="../files/threading.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        案例:多线程爬虫+json存储
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="files/dt.html">
            
                
                    <a href="../files/dt.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        动态渲染页面爬取
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="files/dt01.html">
            
                
                    <a href="../files/dt01.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        动态html
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="files/dt02.html">
            
                
                    <a href="../files/dt02.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        selenium+phantosJS
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="files/dt03.html">
            
                
                    <a href="../files/dt03.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        网站模拟登录
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="files/dt04.html">
            
                
                    <a href="../files/dt04.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        动态页面模拟点击
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="files/dt05.html">
            
                
                    <a href="../files/dt05.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        执行js语句
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="files/scrapy.html">
            
                
                    <a href="../files/scrapy.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        Scrapy框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="files/scrapy01.html">
            
                
                    <a href="../files/scrapy01.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        Scrapy安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="files/scrapy02.html">
            
                
                    <a href="../files/scrapy02.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        Scrapy shell
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="files/scrapy03.html">
            
                
                    <a href="../files/scrapy03.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.3.</b>
                        
                        Item  Pipeline
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.4" data-path="files/scrapy04.html">
            
                
                    <a href="../files/scrapy04.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.4.</b>
                        
                        Spider
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="5.5" data-path="files/scrapy05.html">
            
                
                    <a href="../files/scrapy05.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.5.</b>
                        
                        CrawlSpider
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.6" data-path="files/scrapy06.html">
            
                
                    <a href="../files/scrapy06.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.6.</b>
                        
                        Request/Response
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.7" data-path="files/scrapy07.html">
            
                
                    <a href="../files/scrapy07.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.7.</b>
                        
                        Downloader Middlewares
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.8" data-path="files/scrapy08.html">
            
                
                    <a href="../files/scrapy08.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.8.</b>
                        
                        settings
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    本书使用 GitBook 发布
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >爬虫</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="crawlspider">CrawlSpider</h1>
<p>&#x901A;&#x8FC7;&#x4E0B;&#x9762;&#x7684;&#x547D;&#x4EE4;&#x53EF;&#x4EE5;&#x5FEB;&#x901F;&#x521B;&#x5EFA; CrawlSpider&#x6A21;&#x677F; &#x7684;&#x4EE3;&#x7801;&#xFF1A;</p>
<blockquote>
<pre><code>scrapy genspider -t crawl tencent tencent.com
</code></pre></blockquote>
<p>&#x4E0A;&#x4E00;&#x4E2A;&#x6848;&#x4F8B;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x901A;&#x8FC7;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#xFF0C;&#x5236;&#x4F5C;&#x4E86;&#x65B0;&#x7684;url&#x4F5C;&#x4E3A;Request&#x8BF7;&#x6C42;&#x53C2;&#x6570;&#xFF0C;&#x73B0;&#x5728;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x6362;&#x4E2A;&#x82B1;&#x6837;...</p>
<pre><code>class scrapy.spiders.CrawlSpider
</code></pre><p>&#x5B83;&#x662F;Spider&#x7684;&#x6D3E;&#x751F;&#x7C7B;&#xFF0C;Spider&#x7C7B;&#x7684;&#x8BBE;&#x8BA1;&#x539F;&#x5219;&#x662F;&#x53EA;&#x722C;&#x53D6;start_url&#x5217;&#x8868;&#x4E2D;&#x7684;&#x7F51;&#x9875;&#xFF0C;&#x800C;CrawlSpider&#x7C7B;&#x5B9A;&#x4E49;&#x4E86;&#x4E00;&#x4E9B;&#x89C4;&#x5219;(rule)&#x6765;&#x63D0;&#x4F9B;&#x8DDF;&#x8FDB;link&#x7684;&#x65B9;&#x4FBF;&#x7684;&#x673A;&#x5236;&#xFF0C;&#x4ECE;&#x722C;&#x53D6;&#x7684;&#x7F51;&#x9875;&#x4E2D;&#x83B7;&#x53D6;link&#x5E76;&#x7EE7;&#x7EED;&#x722C;&#x53D6;&#x7684;&#x5DE5;&#x4F5C;&#x66F4;&#x9002;&#x5408;&#x3002;</p>
<h4 id="&#x6E90;&#x7801;&#x53C2;&#x8003;">&#x6E90;&#x7801;&#x53C2;&#x8003;</h4>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CrawlSpider</span><span class="hljs-params">(Spider)</span>:</span>
    rules = ()
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, *a, **kw)</span>:</span>
        super(CrawlSpider, self).__init__(*a, **kw)
        self._compile_rules()

    <span class="hljs-comment">#&#x9996;&#x5148;&#x8C03;&#x7528;parse()&#x6765;&#x5904;&#x7406;start_urls&#x4E2D;&#x8FD4;&#x56DE;&#x7684;response&#x5BF9;&#x8C61;</span>
    <span class="hljs-comment">#parse()&#x5219;&#x5C06;&#x8FD9;&#x4E9B;response&#x5BF9;&#x8C61;&#x4F20;&#x9012;&#x7ED9;&#x4E86;_parse_response()&#x51FD;&#x6570;&#x5904;&#x7406;&#xFF0C;&#x5E76;&#x8BBE;&#x7F6E;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x4E3A;parse_start_url()</span>
    <span class="hljs-comment">#&#x8BBE;&#x7F6E;&#x4E86;&#x8DDF;&#x8FDB;&#x6807;&#x5FD7;&#x4F4D;True</span>
    <span class="hljs-comment">#parse&#x5C06;&#x8FD4;&#x56DE;item&#x548C;&#x8DDF;&#x8FDB;&#x4E86;&#x7684;Request&#x5BF9;&#x8C61;    </span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">return</span> self._parse_response(response, self.parse_start_url, cb_kwargs={}, follow=<span class="hljs-keyword">True</span>)

    <span class="hljs-comment">#&#x5904;&#x7406;start_url&#x4E2D;&#x8FD4;&#x56DE;&#x7684;response&#xFF0C;&#x9700;&#x8981;&#x91CD;&#x5199;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_start_url</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">return</span> []

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_results</span><span class="hljs-params">(self, response, results)</span>:</span>
        <span class="hljs-keyword">return</span> results

    <span class="hljs-comment">#&#x4ECE;response&#x4E2D;&#x62BD;&#x53D6;&#x7B26;&#x5408;&#x4EFB;&#x4E00;&#x7528;&#x6237;&#x5B9A;&#x4E49;&apos;&#x89C4;&#x5219;&apos;&#x7684;&#x94FE;&#x63A5;&#xFF0C;&#x5E76;&#x6784;&#x9020;&#x6210;Resquest&#x5BF9;&#x8C61;&#x8FD4;&#x56DE;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_requests_to_follow</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isinstance(response, HtmlResponse):
            <span class="hljs-keyword">return</span>
        seen = set()
        <span class="hljs-comment">#&#x62BD;&#x53D6;&#x4E4B;&#x5185;&#x7684;&#x6240;&#x6709;&#x94FE;&#x63A5;&#xFF0C;&#x53EA;&#x8981;&#x901A;&#x8FC7;&#x4EFB;&#x610F;&#x4E00;&#x4E2A;&apos;&#x89C4;&#x5219;&apos;&#xFF0C;&#x5373;&#x8868;&#x793A;&#x5408;&#x6CD5;</span>
        <span class="hljs-keyword">for</span> n, rule <span class="hljs-keyword">in</span> enumerate(self._rules):
            links = [l <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> rule.link_extractor.extract_links(response) <span class="hljs-keyword">if</span> l <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> seen]
            <span class="hljs-comment">#&#x4F7F;&#x7528;&#x7528;&#x6237;&#x6307;&#x5B9A;&#x7684;process_links&#x5904;&#x7406;&#x6BCF;&#x4E2A;&#x8FDE;&#x63A5;</span>
            <span class="hljs-keyword">if</span> links <span class="hljs-keyword">and</span> rule.process_links:
                links = rule.process_links(links)
            <span class="hljs-comment">#&#x5C06;&#x94FE;&#x63A5;&#x52A0;&#x5165;seen&#x96C6;&#x5408;&#xFF0C;&#x4E3A;&#x6BCF;&#x4E2A;&#x94FE;&#x63A5;&#x751F;&#x6210;Request&#x5BF9;&#x8C61;&#xFF0C;&#x5E76;&#x8BBE;&#x7F6E;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x4E3A;_repsonse_downloaded()</span>
            <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> links:
                seen.add(link)
                <span class="hljs-comment">#&#x6784;&#x9020;Request&#x5BF9;&#x8C61;&#xFF0C;&#x5E76;&#x5C06;Rule&#x89C4;&#x5219;&#x4E2D;&#x5B9A;&#x4E49;&#x7684;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x4F5C;&#x4E3A;&#x8FD9;&#x4E2A;Request&#x5BF9;&#x8C61;&#x7684;&#x56DE;&#x8C03;&#x51FD;&#x6570;</span>
                r = Request(url=link.url, callback=self._response_downloaded)
                r.meta.update(rule=n, link_text=link.text)
                <span class="hljs-comment">#&#x5BF9;&#x6BCF;&#x4E2A;Request&#x8C03;&#x7528;process_request()&#x51FD;&#x6570;&#x3002;&#x8BE5;&#x51FD;&#x6570;&#x9ED8;&#x8BA4;&#x4E3A;indentify&#xFF0C;&#x5373;&#x4E0D;&#x505A;&#x4EFB;&#x4F55;&#x5904;&#x7406;&#xFF0C;&#x76F4;&#x63A5;&#x8FD4;&#x56DE;&#x8BE5;Request.</span>
                <span class="hljs-keyword">yield</span> rule.process_request(r)

    <span class="hljs-comment">#&#x5904;&#x7406;&#x901A;&#x8FC7;rule&#x63D0;&#x53D6;&#x51FA;&#x7684;&#x8FDE;&#x63A5;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;item&#x4EE5;&#x53CA;request</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_response_downloaded</span><span class="hljs-params">(self, response)</span>:</span>
        rule = self._rules[response.meta[<span class="hljs-string">&apos;rule&apos;</span>]]
        <span class="hljs-keyword">return</span> self._parse_response(response, rule.callback, rule.cb_kwargs, rule.follow)

    <span class="hljs-comment">#&#x89E3;&#x6790;response&#x5BF9;&#x8C61;&#xFF0C;&#x4F1A;&#x7528;callback&#x89E3;&#x6790;&#x5904;&#x7406;&#x4ED6;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;request&#x6216;Item&#x5BF9;&#x8C61;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_parse_response</span><span class="hljs-params">(self, response, callback, cb_kwargs, follow=True)</span>:</span>
        <span class="hljs-comment">#&#x9996;&#x5148;&#x5224;&#x65AD;&#x662F;&#x5426;&#x8BBE;&#x7F6E;&#x4E86;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x3002;&#xFF08;&#x8BE5;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x53EF;&#x80FD;&#x662F;rule&#x4E2D;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;&#xFF0C;&#x4E5F;&#x53EF;&#x80FD;&#x662F; parse_start_url&#x51FD;&#x6570;&#xFF09;</span>
        <span class="hljs-comment">#&#x5982;&#x679C;&#x8BBE;&#x7F6E;&#x4E86;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#xFF08;parse_start_url()&#xFF09;&#xFF0C;&#x90A3;&#x4E48;&#x9996;&#x5148;&#x7528;parse_start_url()&#x5904;&#x7406;response&#x5BF9;&#x8C61;&#xFF0C;</span>
        <span class="hljs-comment">#&#x7136;&#x540E;&#x518D;&#x4EA4;&#x7ED9;process_results&#x5904;&#x7406;&#x3002;&#x8FD4;&#x56DE;cb_res&#x7684;&#x4E00;&#x4E2A;&#x5217;&#x8868;</span>
        <span class="hljs-keyword">if</span> callback:
            <span class="hljs-comment">#&#x5982;&#x679C;&#x662F;parse&#x8C03;&#x7528;&#x7684;&#xFF0C;&#x5219;&#x4F1A;&#x89E3;&#x6790;&#x6210;Request&#x5BF9;&#x8C61;</span>
            <span class="hljs-comment">#&#x5982;&#x679C;&#x662F;rule callback&#xFF0C;&#x5219;&#x4F1A;&#x89E3;&#x6790;&#x6210;Item</span>
            cb_res = callback(response, **cb_kwargs) <span class="hljs-keyword">or</span> ()
            cb_res = self.process_results(response, cb_res)
            <span class="hljs-keyword">for</span> requests_or_item <span class="hljs-keyword">in</span> iterate_spider_output(cb_res):
                <span class="hljs-keyword">yield</span> requests_or_item

        <span class="hljs-comment">#&#x5982;&#x679C;&#x9700;&#x8981;&#x8DDF;&#x8FDB;&#xFF0C;&#x90A3;&#x4E48;&#x4F7F;&#x7528;&#x5B9A;&#x4E49;&#x7684;Rule&#x89C4;&#x5219;&#x63D0;&#x53D6;&#x5E76;&#x8FD4;&#x56DE;&#x8FD9;&#x4E9B;Request&#x5BF9;&#x8C61;</span>
        <span class="hljs-keyword">if</span> follow <span class="hljs-keyword">and</span> self._follow_links:
            <span class="hljs-comment">#&#x8FD4;&#x56DE;&#x6BCF;&#x4E2A;Request&#x5BF9;&#x8C61;</span>
            <span class="hljs-keyword">for</span> request_or_item <span class="hljs-keyword">in</span> self._requests_to_follow(response):
                <span class="hljs-keyword">yield</span> request_or_item

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_compile_rules</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_method</span><span class="hljs-params">(method)</span>:</span>
            <span class="hljs-keyword">if</span> callable(method):
                <span class="hljs-keyword">return</span> method
            <span class="hljs-keyword">elif</span> isinstance(method, basestring):
                <span class="hljs-keyword">return</span> getattr(self, method, <span class="hljs-keyword">None</span>)

        self._rules = [copy.copy(r) <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> self.rules]
        <span class="hljs-keyword">for</span> rule <span class="hljs-keyword">in</span> self._rules:
            rule.callback = get_method(rule.callback)
            rule.process_links = get_method(rule.process_links)
            rule.process_request = get_method(rule.process_request)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">set_crawler</span><span class="hljs-params">(self, crawler)</span>:</span>
        super(CrawlSpider, self).set_crawler(crawler)
        self._follow_links = crawler.settings.getbool(<span class="hljs-string">&apos;CRAWLSPIDER_FOLLOW_LINKS&apos;</span>, <span class="hljs-keyword">True</span>)
</code></pre>
<p>CrawlSpider&#x7EE7;&#x627F;&#x4E8E;Spider&#x7C7B;&#xFF0C;&#x9664;&#x4E86;&#x7EE7;&#x627F;&#x8FC7;&#x6765;&#x7684;&#x5C5E;&#x6027;&#x5916;&#xFF08;name&#x3001;allow_domains&#xFF09;&#xFF0C;&#x8FD8;&#x63D0;&#x4F9B;&#x4E86;&#x65B0;&#x7684;&#x5C5E;&#x6027;&#x548C;&#x65B9;&#x6CD5;:</p>
<h2 id="rules">rules</h2>
<p>CrawlSpider&#x4F7F;&#x7528;rules&#x6765;&#x51B3;&#x5B9A;&#x722C;&#x866B;&#x7684;&#x722C;&#x53D6;&#x89C4;&#x5219;&#xFF0C;&#x5E76;&#x5C06;&#x5339;&#x914D;&#x540E;&#x7684;url&#x8BF7;&#x6C42;&#x63D0;&#x4EA4;&#x7ED9;&#x5F15;&#x64CE;&#x3002;&#x6240;&#x4EE5;&#x5728;&#x6B63;&#x5E38;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;CrawlSpider&#x4E0D;&#x9700;&#x8981;&#x5355;&#x72EC;&#x624B;&#x52A8;&#x8FD4;&#x56DE;&#x8BF7;&#x6C42;&#x4E86;&#x3002;</p>
<p>&#x5728;rules&#x4E2D;&#x5305;&#x542B;&#x4E00;&#x4E2A;&#x6216;&#x591A;&#x4E2A;Rule&#x5BF9;&#x8C61;&#xFF0C;&#x6BCF;&#x4E2A;Rule&#x5BF9;&#x722C;&#x53D6;&#x7F51;&#x7AD9;&#x7684;&#x52A8;&#x4F5C;&#x5B9A;&#x4E49;&#x4E86;&#x67D0;&#x79CD;&#x7279;&#x5B9A;&#x64CD;&#x4F5C;&#xFF0C;&#x6BD4;&#x5982;&#x63D0;&#x53D6;&#x5F53;&#x524D;&#x76F8;&#x5E94;&#x5185;&#x5BB9;&#x91CC;&#x7684;&#x7279;&#x5B9A;&#x94FE;&#x63A5;&#xFF0C;&#x662F;&#x5426;&#x5BF9;&#x63D0;&#x53D6;&#x7684;&#x94FE;&#x63A5;&#x8DDF;&#x8FDB;&#x722C;&#x53D6;&#xFF0C;&#x5BF9;&#x63D0;&#x4EA4;&#x7684;&#x8BF7;&#x6C42;&#x8BBE;&#x7F6E;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x7B49;&#x3002;</p>
<p>&#x5982;&#x679C;&#x591A;&#x4E2A;rule&#x5339;&#x914D;&#x4E86;&#x76F8;&#x540C;&#x7684;&#x94FE;&#x63A5;&#xFF0C;&#x5219;&#x6839;&#x636E;&#x89C4;&#x5219;&#x5728;&#x672C;&#x96C6;&#x5408;&#x4E2D;&#x88AB;&#x5B9A;&#x4E49;&#x7684;&#x987A;&#x5E8F;&#xFF0C;&#x7B2C;&#x4E00;&#x4E2A;&#x4F1A;&#x88AB;&#x4F7F;&#x7528;&#x3002;</p>
<pre><code class="lang-python">class scrapy.spiders.Rule(
        link_extractor,
        callback = None,
        cb_kwargs = None,
        follow = None,
        process_links = None,
        process_request = None
)
</code></pre>
<ul>
<li><p><code>link_extractor</code>&#xFF1A;&#x662F;&#x4E00;&#x4E2A;Link Extractor&#x5BF9;&#x8C61;&#xFF0C;&#x7528;&#x4E8E;&#x5B9A;&#x4E49;&#x9700;&#x8981;&#x63D0;&#x53D6;&#x7684;&#x94FE;&#x63A5;&#x3002;</p>
</li>
<li><p><code>callback</code>&#xFF1A; &#x4ECE;link_extractor&#x4E2D;&#x6BCF;&#x83B7;&#x53D6;&#x5230;&#x94FE;&#x63A5;&#x65F6;&#xFF0C;&#x53C2;&#x6570;&#x6240;&#x6307;&#x5B9A;&#x7684;&#x503C;&#x4F5C;&#x4E3A;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#xFF0C;&#x8BE5;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x63A5;&#x53D7;&#x4E00;&#x4E2A;response&#x4F5C;&#x4E3A;&#x5176;&#x7B2C;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x3002;</p>
<blockquote>
<p>&#x6CE8;&#x610F;&#xFF1A;&#x5F53;&#x7F16;&#x5199;&#x722C;&#x866B;&#x89C4;&#x5219;&#x65F6;&#xFF0C;&#x907F;&#x514D;&#x4F7F;&#x7528;parse&#x4F5C;&#x4E3A;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x3002;&#x7531;&#x4E8E;CrawlSpider&#x4F7F;&#x7528;parse&#x65B9;&#x6CD5;&#x6765;&#x5B9E;&#x73B0;&#x5176;&#x903B;&#x8F91;&#xFF0C;&#x5982;&#x679C;&#x8986;&#x76D6;&#x4E86; parse&#x65B9;&#x6CD5;&#xFF0C;crawl spider&#x5C06;&#x4F1A;&#x8FD0;&#x884C;&#x5931;&#x8D25;&#x3002;</p>
</blockquote>
</li>
<li><p><code>follow</code>&#xFF1A;&#x662F;&#x4E00;&#x4E2A;&#x5E03;&#x5C14;(boolean)&#x503C;&#xFF0C;&#x6307;&#x5B9A;&#x4E86;&#x6839;&#x636E;&#x8BE5;&#x89C4;&#x5219;&#x4ECE;response&#x63D0;&#x53D6;&#x7684;&#x94FE;&#x63A5;&#x662F;&#x5426;&#x9700;&#x8981;&#x8DDF;&#x8FDB;&#x3002; &#x5982;&#x679C;callback&#x4E3A;None&#xFF0C;follow &#x9ED8;&#x8BA4;&#x8BBE;&#x7F6E;&#x4E3A;True &#xFF0C;&#x5426;&#x5219;&#x9ED8;&#x8BA4;&#x4E3A;False&#x3002;</p>
</li>
<li><p><code>process_links</code>&#xFF1A;&#x6307;&#x5B9A;&#x8BE5;spider&#x4E2D;&#x54EA;&#x4E2A;&#x7684;&#x51FD;&#x6570;&#x5C06;&#x4F1A;&#x88AB;&#x8C03;&#x7528;&#xFF0C;&#x4ECE;link_extractor&#x4E2D;&#x83B7;&#x53D6;&#x5230;&#x94FE;&#x63A5;&#x5217;&#x8868;&#x65F6;&#x5C06;&#x4F1A;&#x8C03;&#x7528;&#x8BE5;&#x51FD;&#x6570;&#x3002;&#x8BE5;&#x65B9;&#x6CD5;&#x4E3B;&#x8981;&#x7528;&#x6765;&#x8FC7;&#x6EE4;&#x3002;</p>
</li>
<li><p><code>process_request</code>&#xFF1A;&#x6307;&#x5B9A;&#x8BE5;spider&#x4E2D;&#x54EA;&#x4E2A;&#x7684;&#x51FD;&#x6570;&#x5C06;&#x4F1A;&#x88AB;&#x8C03;&#x7528;&#xFF0C; &#x8BE5;&#x89C4;&#x5219;&#x63D0;&#x53D6;&#x5230;&#x6BCF;&#x4E2A;request&#x65F6;&#x90FD;&#x4F1A;&#x8C03;&#x7528;&#x8BE5;&#x51FD;&#x6570;&#x3002; (&#x7528;&#x6765;&#x8FC7;&#x6EE4;request)</p>
</li>
</ul>
<h2 id="linkextractors">LinkExtractors</h2>
<pre><code class="lang-python">class scrapy.linkextractors.LinkExtractor
</code></pre>
<p>Link Extractors &#x7684;&#x76EE;&#x7684;&#x5F88;&#x7B80;&#x5355;: &#x63D0;&#x53D6;&#x94FE;&#x63A5;&#xFF61;</p>
<p>&#x6BCF;&#x4E2A;LinkExtractor&#x6709;&#x552F;&#x4E00;&#x7684;&#x516C;&#x5171;&#x65B9;&#x6CD5;&#x662F; extract_links()&#xFF0C;&#x5B83;&#x63A5;&#x6536;&#x4E00;&#x4E2A; Response &#x5BF9;&#x8C61;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; scrapy.link.Link &#x5BF9;&#x8C61;&#x3002;</p>
<p>Link Extractors&#x8981;&#x5B9E;&#x4F8B;&#x5316;&#x4E00;&#x6B21;&#xFF0C;&#x5E76;&#x4E14; extract_links &#x65B9;&#x6CD5;&#x4F1A;&#x6839;&#x636E;&#x4E0D;&#x540C;&#x7684; response &#x8C03;&#x7528;&#x591A;&#x6B21;&#x63D0;&#x53D6;&#x94FE;&#x63A5;&#xFF61;</p>
<pre><code class="lang-python">class scrapy.linkextractors.LinkExtractor(
    allow = (),
    deny = (),
    allow_domains = (),
    deny_domains = (),
    deny_extensions = None,
    restrict_xpaths = (),
    tags = (&apos;a&apos;,&apos;area&apos;),
    attrs = (&apos;href&apos;),
    canonicalize = True,
    unique = True,
    process_value = None
)
</code></pre>
<p>&#x4E3B;&#x8981;&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>allow</code>&#xFF1A;&#x6EE1;&#x8DB3;&#x62EC;&#x53F7;&#x4E2D;&#x201C;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x201D;&#x7684;URL&#x4F1A;&#x88AB;&#x63D0;&#x53D6;&#xFF0C;&#x5982;&#x679C;&#x4E3A;&#x7A7A;&#xFF0C;&#x5219;&#x5168;&#x90E8;&#x5339;&#x914D;&#x3002;</li>
<li><code>deny</code>&#xFF1A;&#x6EE1;&#x8DB3;&#x62EC;&#x53F7;&#x4E2D;&#x201C;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x201D;&#x7684;URL&#x4E00;&#x5B9A;&#x4E0D;&#x63D0;&#x53D6;&#xFF08;&#x4F18;&#x5148;&#x7EA7;&#x9AD8;&#x4E8E;allow&#xFF09;&#x3002;</li>
<li><code>allow_domains</code>&#xFF1A;&#x4F1A;&#x88AB;&#x63D0;&#x53D6;&#x7684;&#x94FE;&#x63A5;&#x7684;domains&#x3002;</li>
<li><code>deny_domains</code>&#xFF1A;&#x4E00;&#x5B9A;&#x4E0D;&#x4F1A;&#x88AB;&#x63D0;&#x53D6;&#x94FE;&#x63A5;&#x7684;domains&#x3002;</li>
<li><code>restrict_xpaths</code>&#xFF1A;&#x4F7F;&#x7528;xpath&#x8868;&#x8FBE;&#x5F0F;&#xFF0C;&#x548C;allow&#x5171;&#x540C;&#x4F5C;&#x7528;&#x8FC7;&#x6EE4;&#x94FE;&#x63A5;&#x3002;</li>
</ul>
<h2 id="&#x722C;&#x53D6;&#x89C4;&#x5219;crawling-rules">&#x722C;&#x53D6;&#x89C4;&#x5219;(Crawling rules)</h2>
<p>&#x7EE7;&#x7EED;&#x7528;&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x4E3A;&#x4F8B;&#xFF0C;&#x7ED9;&#x51FA;&#x914D;&#x5408;rule&#x4F7F;&#x7528;CrawlSpider&#x7684;&#x4F8B;&#x5B50;:</p>
<ol>
<li><p>&#x9996;&#x5148;&#x8FD0;&#x884C;</p>
<pre><code class="lang-sh"> scrapy shell <span class="hljs-string">&quot;http://hr.tencent.com/position.php?&amp;start=0#a&quot;</span>
</code></pre>
</li>
<li><p>&#x5BFC;&#x5165;LinkExtractor&#xFF0C;&#x521B;&#x5EFA;LinkExtractor&#x5B9E;&#x4F8B;&#x5BF9;&#x8C61;&#x3002;&#xFF1A;</p>
<pre><code class="lang-python"> <span class="hljs-keyword">from</span> scrapy.linkextractors <span class="hljs-keyword">import</span> LinkExtractor

 page_lx = LinkExtractor(allow=(<span class="hljs-string">&apos;position.php?&amp;start=\d+&apos;</span>))
</code></pre>
<blockquote>
<p>allow : LinkExtractor&#x5BF9;&#x8C61;&#x6700;&#x91CD;&#x8981;&#x7684;&#x53C2;&#x6570;&#x4E4B;&#x4E00;&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#xFF0C;&#x5FC5;&#x987B;&#x8981;&#x5339;&#x914D;&#x8FD9;&#x4E2A;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;(&#x6216;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x5217;&#x8868;)&#x7684;URL&#x624D;&#x4F1A;&#x88AB;&#x63D0;&#x53D6;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x7ED9;&#x51FA;(&#x6216;&#x4E3A;&#x7A7A;), &#x5B83;&#x4F1A;&#x5339;&#x914D;&#x6240;&#x6709;&#x7684;&#x94FE;&#x63A5;&#xFF61;</p>
<p>deny : &#x7528;&#x6CD5;&#x540C;allow&#xFF0C;&#x53EA;&#x4E0D;&#x8FC7;&#x4E0E;&#x8FD9;&#x4E2A;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x5339;&#x914D;&#x7684;URL&#x4E0D;&#x4F1A;&#x88AB;&#x63D0;&#x53D6;)&#xFF61;&#x5B83;&#x7684;&#x4F18;&#x5148;&#x7EA7;&#x9AD8;&#x4E8E; allow &#x7684;&#x53C2;&#x6570;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x7ED9;&#x51FA;(&#x6216;None), &#x5C06;&#x4E0D;&#x6392;&#x9664;&#x4EFB;&#x4F55;&#x94FE;&#x63A5;&#xFF61;</p>
</blockquote>
</li>
<li><p>&#x8C03;&#x7528;LinkExtractor&#x5B9E;&#x4F8B;&#x7684;extract_links()&#x65B9;&#x6CD5;&#x67E5;&#x8BE2;&#x5339;&#x914D;&#x7ED3;&#x679C;&#xFF1A;</p>
<pre><code class="lang-python"> page_lx.extract_links(response)
</code></pre>
</li>
<li><p>&#x6CA1;&#x6709;&#x67E5;&#x5230;&#xFF1A;</p>
<pre><code class="lang-python"> []
</code></pre>
</li>
<li><p>&#x6CE8;&#x610F;&#x8F6C;&#x4E49;&#x5B57;&#x7B26;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x7EE7;&#x7EED;&#x91CD;&#x65B0;&#x5339;&#x914D;&#xFF1A;</p>
<pre><code class="lang-python"> page_lx = LinkExtractor(allow=(<span class="hljs-string">&apos;position\.php\?&amp;start=\d+&apos;</span>))
 <span class="hljs-comment"># page_lx = LinkExtractor(allow = (&apos;start=\d+&apos;))</span>

 page_lx.extract_links(response)
</code></pre>
</li>
</ol>
<p><img src="../images/tencent_rule.png" alt="img"></p>
<h2 id="crawlspider-&#x7248;&#x672C;">CrawlSpider &#x7248;&#x672C;</h2>
<p>&#x90A3;&#x4E48;&#xFF0C;scrapy shell&#x6D4B;&#x8BD5;&#x5B8C;&#x6210;&#x4E4B;&#x540E;&#xFF0C;&#x4FEE;&#x6539;&#x4EE5;&#x4E0B;&#x4EE3;&#x7801;</p>
<pre><code class="lang-python"><span class="hljs-comment">#&#x63D0;&#x53D6;&#x5339;&#x914D; &apos;http://hr.tencent.com/position.php?&amp;start=\d+&apos;&#x7684;&#x94FE;&#x63A5;</span>
page_lx = LinkExtractor(allow = (<span class="hljs-string">&apos;start=\d+&apos;</span>))

rules = [
    <span class="hljs-comment">#&#x63D0;&#x53D6;&#x5339;&#x914D;,&#x5E76;&#x4F7F;&#x7528;spider&#x7684;parse&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x5206;&#x6790;;&#x5E76;&#x8DDF;&#x8FDB;&#x94FE;&#x63A5;(&#x6CA1;&#x6709;callback&#x610F;&#x5473;&#x7740;follow&#x9ED8;&#x8BA4;&#x4E3A;True)</span>
    Rule(page_lx, callback = <span class="hljs-string">&apos;parse&apos;</span>, follow = <span class="hljs-keyword">True</span>)
]
</code></pre>
<p><strong>&#x8FD9;&#x4E48;&#x5199;&#x5BF9;&#x5417;&#xFF1F;</strong></p>
<p><strong>&#x4E0D;&#x5BF9;&#xFF01;&#x5343;&#x4E07;&#x8BB0;&#x4F4F; callback &#x5343;&#x4E07;&#x4E0D;&#x80FD;&#x5199; parse&#xFF0C;&#x518D;&#x6B21;&#x5F3A;&#x8C03;&#xFF1A;&#x7531;&#x4E8E;CrawlSpider&#x4F7F;&#x7528;parse&#x65B9;&#x6CD5;&#x6765;&#x5B9E;&#x73B0;&#x5176;&#x903B;&#x8F91;&#xFF0C;&#x5982;&#x679C;&#x8986;&#x76D6;&#x4E86; parse&#x65B9;&#x6CD5;&#xFF0C;crawl spider&#x5C06;&#x4F1A;&#x8FD0;&#x884C;&#x5931;&#x8D25;&#x3002;</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> scrapy.linkextractors <span class="hljs-keyword">import</span> LinkExtractor
<span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> CrawlSpider, Rule


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TecentSpider</span><span class="hljs-params">(CrawlSpider)</span>:</span>
    name = <span class="hljs-string">&apos;tecent&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;hr.tencent.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;http://hr.tencent.com/position.php?&amp;start=0&apos;</span>]
    page_lx = LinkExtractor(allow=<span class="hljs-string">r&apos;start=\d+&apos;</span>)
    <span class="hljs-comment">#position.php?&amp;start=10#a</span>
    rules = (
        Rule(page_lx, callback=<span class="hljs-string">&apos;parse_item&apos;</span>, follow=<span class="hljs-keyword">True</span>),
    )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_item</span><span class="hljs-params">(self, response)</span>:</span>
        items = response.xpath(<span class="hljs-string">&apos;//*[contains(@class,&quot;odd&quot;) or contains(@class,&quot;even&quot;)]&apos;</span>)
        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> items:
            temp = dict(
                position=item.xpath(<span class="hljs-string">&quot;./td[1]/a/text()&quot;</span>).extract()[<span class="hljs-number">0</span>],
                detailLink=<span class="hljs-string">&quot;http://hr.tencent.com/&quot;</span> + item.xpath(<span class="hljs-string">&quot;./td[1]/a/@href&quot;</span>).extract()[<span class="hljs-number">0</span>],
                type=item.xpath(<span class="hljs-string">&apos;./td[2]/text()&apos;</span>).extract()[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> len(
                    item.xpath(<span class="hljs-string">&apos;./td[2]/text()&apos;</span>).extract()) &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-keyword">None</span>,
                need_num=item.xpath(<span class="hljs-string">&apos;./td[3]/text()&apos;</span>).extract()[<span class="hljs-number">0</span>],
                location=item.xpath(<span class="hljs-string">&apos;./td[4]/text()&apos;</span>).extract()[<span class="hljs-number">0</span>],
                publish_time=item.xpath(<span class="hljs-string">&apos;./td[5]/text()&apos;</span>).extract()[<span class="hljs-number">0</span>]
            )
            print(temp)
            <span class="hljs-keyword">yield</span> temp

    <span class="hljs-comment"># parse() &#x65B9;&#x6CD5;&#x4E0D;&#x9700;&#x8981;&#x91CD;&#x5199;     </span>
    <span class="hljs-comment"># def parse(self, response):                                              </span>
    <span class="hljs-comment">#     pass</span>
</code></pre>
<p>&#x8FD0;&#x884C;&#xFF1A; <code>scrapy crawl tencent</code></p>
<h2 id="logging">Logging</h2>
<p>Scrapy&#x63D0;&#x4F9B;&#x4E86;log&#x529F;&#x80FD;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7; logging &#x6A21;&#x5757;&#x4F7F;&#x7528;&#x3002;</p>
<blockquote>
<p>&#x53EF;&#x4EE5;&#x4FEE;&#x6539;&#x914D;&#x7F6E;&#x6587;&#x4EF6;settings.py&#xFF0C;&#x4EFB;&#x610F;&#x4F4D;&#x7F6E;&#x6DFB;&#x52A0;&#x4E0B;&#x9762;&#x4E24;&#x884C;&#xFF0C;&#x6548;&#x679C;&#x4F1A;&#x6E05;&#x723D;&#x5F88;&#x591A;&#x3002;</p>
</blockquote>
<pre><code>LOG_FILE = &quot;TencentSpider.log&quot;
LOG_LEVEL = &quot;INFO&quot;
</code></pre><h4 id="log-levels">Log levels</h4>
<ul>
<li>Scrapy&#x63D0;&#x4F9B;5&#x5C42;logging&#x7EA7;&#x522B;:</li>
<li>CRITICAL - &#x4E25;&#x91CD;&#x9519;&#x8BEF;(critical)</li>
<li>ERROR - &#x4E00;&#x822C;&#x9519;&#x8BEF;(regular errors)</li>
<li>WARNING - &#x8B66;&#x544A;&#x4FE1;&#x606F;(warning messages)</li>
<li>INFO - &#x4E00;&#x822C;&#x4FE1;&#x606F;(informational messages)</li>
<li>DEBUG - &#x8C03;&#x8BD5;&#x4FE1;&#x606F;(debugging messages)</li>
</ul>
<h4 id="logging&#x8BBE;&#x7F6E;">logging&#x8BBE;&#x7F6E;</h4>
<p>&#x901A;&#x8FC7;&#x5728;setting.py&#x4E2D;&#x8FDB;&#x884C;&#x4EE5;&#x4E0B;&#x8BBE;&#x7F6E;&#x53EF;&#x4EE5;&#x88AB;&#x7528;&#x6765;&#x914D;&#x7F6E;logging:</p>
<ol>
<li><code>LOG_ENABLED</code> &#x9ED8;&#x8BA4;: True&#xFF0C;&#x542F;&#x7528;logging</li>
<li><code>LOG_ENCODING</code> &#x9ED8;&#x8BA4;: &apos;utf-8&apos;&#xFF0C;logging&#x4F7F;&#x7528;&#x7684;&#x7F16;&#x7801;</li>
<li><code>LOG_FILE</code> &#x9ED8;&#x8BA4;: None&#xFF0C;&#x5728;&#x5F53;&#x524D;&#x76EE;&#x5F55;&#x91CC;&#x521B;&#x5EFA;logging&#x8F93;&#x51FA;&#x6587;&#x4EF6;&#x7684;&#x6587;&#x4EF6;&#x540D;</li>
<li><code>LOG_LEVEL</code> &#x9ED8;&#x8BA4;: &apos;DEBUG&apos;&#xFF0C;log&#x7684;&#x6700;&#x4F4E;&#x7EA7;&#x522B;</li>
<li><code>LOG_STDOUT</code> &#x9ED8;&#x8BA4;: False &#x5982;&#x679C;&#x4E3A; True&#xFF0C;&#x8FDB;&#x7A0B;&#x6240;&#x6709;&#x7684;&#x6807;&#x51C6;&#x8F93;&#x51FA;(&#x53CA;&#x9519;&#x8BEF;)&#x5C06;&#x4F1A;&#x88AB;&#x91CD;&#x5B9A;&#x5411;&#x5230;log&#x4E2D;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x6267;&#x884C; print &quot;hello&quot; &#xFF0C;&#x5176;&#x5C06;&#x4F1A;&#x5728;Scrapy log&#x4E2D;&#x663E;&#x793A;&#x3002;</li>
</ol>
<footer class="page-footer"><span class="copyright">CopyRight&#xA9;2019 &#x54B8;&#x9C7C;&#x8D85;&#x4EBA; all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A;
2019-03-28 01:28:41
</span></footer>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../files/scrapy04.html" class="navigation navigation-prev " aria-label="Previous page: Spider"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../files/scrapy06.html" class="navigation navigation-next " aria-label="Next page: Request/Response"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-toggle-chapters/toggle.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-splitter/splitter.js"></script>
    

    
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-mcqx/js.cookie.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-mcqx/mcqx.js"></script>
    

    
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fbqx/fbqx.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fbqx/js.cookie.js"></script>
    

    
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sectionx/sectionx.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"tbfed-pagefooter":{"copyright":"CopyRight©2019 咸鱼超人","modify_label":"该文件修订时间：","modify_format":"YYYY-MM-DD HH:mm:ss"},"sectionx":{"tag":"b"},"toggle-chapters":{},"splitter":{},"emphasize":{},"mcqx":{},"katex":{},"fbqx":{},"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        <!-- body:end -->
    </body>
    <!-- End of book 爬虫 -->
</html>
